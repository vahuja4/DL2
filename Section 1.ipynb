{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lecture 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/bin/sh: 1: python: not found\r\n"
     ]
    }
   ],
   "source": [
    "!python -V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.7.3\r\n"
     ]
    }
   ],
   "source": [
    "!python3 -V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mtorch-1.1.0-cp36-cp36m-linux_x86_64.whl is not a supported wheel on this platform.\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "!python3 -m pip install https://download.pytorch.org/whl/cu100/torch-1.1.0-cp36-cp36m-linux_x86_64.whl --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torchvision==0.3.0 from https://download.pytorch.org/whl/cu100/torchvision-0.3.0-cp36-cp36m-linux_x86_64.whl in /usr/local/lib/python3.6/dist-packages (0.3.0)\r\n",
      "Requirement already satisfied: six in /home/qamaruddin/.local/lib/python3.6/site-packages (from torchvision==0.3.0) (1.11.0)\r\n",
      "Requirement already satisfied: torch>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from torchvision==0.3.0) (1.1.0)\r\n",
      "Requirement already satisfied: pillow>=4.1.1 in /home/qamaruddin/.local/lib/python3.6/site-packages (from torchvision==0.3.0) (5.3.0)\r\n",
      "Requirement already satisfied: numpy in /home/qamaruddin/.local/lib/python3.6/site-packages (from torchvision==0.3.0) (1.16.1)\r\n"
     ]
    }
   ],
   "source": [
    "!python3 -m pip install https://download.pytorch.org/whl/cu100/torchvision-0.3.0-cp36-cp36m-linux_x86_64.whl --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.1.0\n",
      "0.3.0\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "\n",
    "\n",
    "print(torch.__version__)\n",
    "print(torchvision.__version__)\n",
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bonus Tip\n",
    "\n",
    "\n",
    "##### Jupyter Notebook Remote Server"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Terminal Only\n",
    "`\n",
    "$ jupyter notebook --port 8888 --no-browser --ip 0.0.0.0\n",
    "`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Windows Troubleshooting\n",
    "\n",
    "Reference: <a href=\"https://pytorch.org/docs/stable/notes/windows.html\" target=\"_BLANK\">WINDOWS FAQ</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LeNet-5 Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "\n",
    "class LeNet5(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        \n",
    "        super(LeNet5, self).__init__()\n",
    "        \n",
    "        self.convnet = torch.nn.Sequential(\n",
    "            # Conv Block 1\n",
    "            torch.nn.Conv2d(\n",
    "                in_channels=1,\n",
    "                out_channels=6,\n",
    "                kernel_size=(5, 5),\n",
    "                stride=1,\n",
    "                bias=True\n",
    "            ),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.MaxPool2d(\n",
    "                kernel_size=(2, 2),\n",
    "                stride=2\n",
    "            ),\n",
    "            # Conv Block 2\n",
    "            torch.nn.Conv2d(\n",
    "                in_channels=6,\n",
    "                out_channels=16,\n",
    "                kernel_size=(5, 5),\n",
    "                stride=1,\n",
    "                bias=True\n",
    "            ),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.MaxPool2d(\n",
    "                kernel_size=(2, 2),\n",
    "                stride=2\n",
    "            ),\n",
    "            # Conv Block 3\n",
    "            torch.nn.Conv2d(\n",
    "                in_channels=16,\n",
    "                out_channels=120,\n",
    "                kernel_size=(5, 5),\n",
    "                stride=1,\n",
    "                bias=True\n",
    "            ),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.MaxPool2d(\n",
    "                kernel_size=(2, 2),\n",
    "                stride=2\n",
    "            )\n",
    "        )\n",
    "        \n",
    "        self.fcn = torch.nn.Sequential(\n",
    "            # Fully Connected Layer 1\n",
    "            torch.nn.Linear(\n",
    "                in_features=120,\n",
    "                out_features=84,\n",
    "                bias=True\n",
    "            ),\n",
    "            torch.nn.ReLU(),\n",
    "            # Classifier Layer 2\n",
    "            torch.nn.Linear(\n",
    "                in_features=84,\n",
    "                out_features=10,\n",
    "                bias=True\n",
    "            ),\n",
    "            torch.nn.Softmax(dim=1)\n",
    "        )\n",
    "\n",
    "    def forward(self, batch):\n",
    "        ret = self.convnet(batch)\n",
    "        ret = ret.view(batch.size(0), -1)\n",
    "        ret = self.fcn(ret)\n",
    "        return ret"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualize Network ( Bonus )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting graphviz\n",
      "  Downloading https://files.pythonhosted.org/packages/af/ae/e1c63ac4c531d69a7960a99af99e184d4f3da15e29f67767c4252bf19cce/graphviz-0.11-py2.py3-none-any.whl\n",
      "Collecting hiddenlayer\n",
      "  Downloading https://files.pythonhosted.org/packages/b5/80/f284e0441945341c2fe669d70a17277746baf891fe4e517dcbe7784cbf24/hiddenlayer-0.2-py3-none-any.whl\n",
      "Installing collected packages: graphviz, hiddenlayer\n",
      "Successfully installed graphviz-0.11 hiddenlayer-0.2\n"
     ]
    }
   ],
   "source": [
    "! python3 -m pip install graphviz hiddenlayer --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.40.1 (20161225.0304)\n",
       " -->\n",
       "<!-- Title: %3 Pages: 1 -->\n",
       "<svg width=\"430pt\" height=\"855pt\"\n",
       " viewBox=\"0.00 0.00 430.00 855.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(72 819)\">\n",
       "<title>%3</title>\n",
       "<polygon fill=\"#ffffff\" stroke=\"transparent\" points=\"-72,36 -72,-819 358,-819 358,36 -72,36\"/>\n",
       "<!-- LeNet5/Sequential[convnet]/MaxPool2d[2]/outputs/13 -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>LeNet5/Sequential[convnet]/MaxPool2d[2]/outputs/13</title>\n",
       "<polygon fill=\"#e8e8e8\" stroke=\"#000000\" points=\"268,-700 198,-700 198,-664 268,-664 268,-700\"/>\n",
       "<text text-anchor=\"start\" x=\"206\" y=\"-679\" font-family=\"Times\" font-size=\"10.00\" fill=\"#000000\">MaxPool2x2</text>\n",
       "</g>\n",
       "<!-- 9982070002344264092 -->\n",
       "<g id=\"node15\" class=\"node\">\n",
       "<title>9982070002344264092</title>\n",
       "<polygon fill=\"#e8e8e8\" stroke=\"#000000\" points=\"275,-617 191,-617 191,-581 275,-581 275,-617\"/>\n",
       "<text text-anchor=\"start\" x=\"199\" y=\"-596\" font-family=\"Times\" font-size=\"10.00\" fill=\"#000000\">Conv5x5 &gt; Relu</text>\n",
       "</g>\n",
       "<!-- LeNet5/Sequential[convnet]/MaxPool2d[2]/outputs/13&#45;&gt;9982070002344264092 -->\n",
       "<g id=\"edge11\" class=\"edge\">\n",
       "<title>LeNet5/Sequential[convnet]/MaxPool2d[2]/outputs/13&#45;&gt;9982070002344264092</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M233,-663.9902C233,-653.2963 233,-639.4994 233,-627.3706\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"236.5001,-627.2612 233,-617.2612 229.5001,-627.2613 236.5001,-627.2612\"/>\n",
       "<text text-anchor=\"middle\" x=\"257\" y=\"-638\" font-family=\"Times\" font-size=\"10.00\" fill=\"#000000\">1x6x14x14</text>\n",
       "</g>\n",
       "<!-- LeNet5/Sequential[convnet]/MaxPool2d[5]/outputs/16 -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>LeNet5/Sequential[convnet]/MaxPool2d[5]/outputs/16</title>\n",
       "<polygon fill=\"#e8e8e8\" stroke=\"#000000\" points=\"268,-534 198,-534 198,-498 268,-498 268,-534\"/>\n",
       "<text text-anchor=\"start\" x=\"206\" y=\"-513\" font-family=\"Times\" font-size=\"10.00\" fill=\"#000000\">MaxPool2x2</text>\n",
       "</g>\n",
       "<!-- 6016725258550978689 -->\n",
       "<g id=\"node16\" class=\"node\">\n",
       "<title>6016725258550978689</title>\n",
       "<polygon fill=\"#e8e8e8\" stroke=\"#000000\" points=\"275,-451 191,-451 191,-415 275,-415 275,-451\"/>\n",
       "<text text-anchor=\"start\" x=\"199\" y=\"-430\" font-family=\"Times\" font-size=\"10.00\" fill=\"#000000\">Conv5x5 &gt; Relu</text>\n",
       "</g>\n",
       "<!-- LeNet5/Sequential[convnet]/MaxPool2d[5]/outputs/16&#45;&gt;6016725258550978689 -->\n",
       "<g id=\"edge13\" class=\"edge\">\n",
       "<title>LeNet5/Sequential[convnet]/MaxPool2d[5]/outputs/16&#45;&gt;6016725258550978689</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M233,-497.9902C233,-487.2963 233,-473.4994 233,-461.3706\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"236.5001,-461.2612 233,-451.2612 229.5001,-461.2613 236.5001,-461.2612\"/>\n",
       "<text text-anchor=\"middle\" x=\"254.5\" y=\"-472\" font-family=\"Times\" font-size=\"10.00\" fill=\"#000000\">1x16x5x5</text>\n",
       "</g>\n",
       "<!-- LeNet5/Sequential[convnet]/MaxPool2d[8]/outputs/19 -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>LeNet5/Sequential[convnet]/MaxPool2d[8]/outputs/19</title>\n",
       "<polygon fill=\"#e8e8e8\" stroke=\"#000000\" points=\"262,-368 192,-368 192,-332 262,-332 262,-368\"/>\n",
       "<text text-anchor=\"start\" x=\"200\" y=\"-347\" font-family=\"Times\" font-size=\"10.00\" fill=\"#000000\">MaxPool2x2</text>\n",
       "</g>\n",
       "<!-- LeNet5/outputs/27 -->\n",
       "<g id=\"node11\" class=\"node\">\n",
       "<title>LeNet5/outputs/27</title>\n",
       "<polygon fill=\"#e8e8e8\" stroke=\"#000000\" points=\"208,-285 154,-285 154,-249 208,-249 208,-285\"/>\n",
       "<text text-anchor=\"start\" x=\"164\" y=\"-264\" font-family=\"Times\" font-size=\"10.00\" fill=\"#000000\">Reshape</text>\n",
       "</g>\n",
       "<!-- LeNet5/Sequential[convnet]/MaxPool2d[8]/outputs/19&#45;&gt;LeNet5/outputs/27 -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>LeNet5/Sequential[convnet]/MaxPool2d[8]/outputs/19&#45;&gt;LeNet5/outputs/27</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M217.0187,-331.9902C210.9123,-320.9722 202.9805,-306.6604 196.115,-294.2727\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"199.0295,-292.3112 191.1207,-285.2612 192.9069,-295.7044 199.0295,-292.3112\"/>\n",
       "<text text-anchor=\"middle\" x=\"230\" y=\"-306\" font-family=\"Times\" font-size=\"10.00\" fill=\"#000000\">1x120x1x1</text>\n",
       "</g>\n",
       "<!-- LeNet5/outputs/20 -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>LeNet5/outputs/20</title>\n",
       "<polygon fill=\"#e8e8e8\" stroke=\"#000000\" points=\"54,-617 0,-617 0,-581 54,-581 54,-617\"/>\n",
       "<text text-anchor=\"start\" x=\"9\" y=\"-596\" font-family=\"Times\" font-size=\"10.00\" fill=\"#000000\">Constant</text>\n",
       "</g>\n",
       "<!-- LeNet5/outputs/22 -->\n",
       "<g id=\"node6\" class=\"node\">\n",
       "<title>LeNet5/outputs/22</title>\n",
       "<polygon fill=\"#e8e8e8\" stroke=\"#000000\" points=\"90,-534 36,-534 36,-498 90,-498 90,-534\"/>\n",
       "<text text-anchor=\"start\" x=\"49\" y=\"-513\" font-family=\"Times\" font-size=\"10.00\" fill=\"#000000\">Gather</text>\n",
       "</g>\n",
       "<!-- LeNet5/outputs/20&#45;&gt;LeNet5/outputs/22 -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>LeNet5/outputs/20&#45;&gt;LeNet5/outputs/22</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M34.8115,-580.9902C39.5435,-570.0802 45.6763,-555.9407 51.0126,-543.6376\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"54.3112,-544.8282 55.0795,-534.2612 47.8893,-542.0427 54.3112,-544.8282\"/>\n",
       "</g>\n",
       "<!-- LeNet5/outputs/21 -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>LeNet5/outputs/21</title>\n",
       "<polygon fill=\"#e8e8e8\" stroke=\"#000000\" points=\"126,-617 72,-617 72,-581 126,-581 126,-617\"/>\n",
       "<text text-anchor=\"start\" x=\"87\" y=\"-596\" font-family=\"Times\" font-size=\"10.00\" fill=\"#000000\">Shape</text>\n",
       "</g>\n",
       "<!-- LeNet5/outputs/21&#45;&gt;LeNet5/outputs/22 -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>LeNet5/outputs/21&#45;&gt;LeNet5/outputs/22</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M91.1885,-580.9902C86.4565,-570.0802 80.3237,-555.9407 74.9874,-543.6376\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"78.1107,-542.0427 70.9205,-534.2612 71.6888,-544.8282 78.1107,-542.0427\"/>\n",
       "</g>\n",
       "<!-- /outputs/24 -->\n",
       "<g id=\"node8\" class=\"node\">\n",
       "<title>/outputs/24</title>\n",
       "<polygon fill=\"#e8e8e8\" stroke=\"#000000\" points=\"93.5,-451 32.5,-451 32.5,-415 93.5,-415 93.5,-451\"/>\n",
       "<text text-anchor=\"start\" x=\"41\" y=\"-430\" font-family=\"Times\" font-size=\"10.00\" fill=\"#000000\">Unsqueeze</text>\n",
       "</g>\n",
       "<!-- LeNet5/outputs/22&#45;&gt;/outputs/24 -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>LeNet5/outputs/22&#45;&gt;/outputs/24</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M63,-497.9902C63,-487.2963 63,-473.4994 63,-461.3706\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"66.5001,-461.2612 63,-451.2612 59.5001,-461.2613 66.5001,-461.2612\"/>\n",
       "</g>\n",
       "<!-- LeNet5/outputs/23 -->\n",
       "<g id=\"node7\" class=\"node\">\n",
       "<title>LeNet5/outputs/23</title>\n",
       "<polygon fill=\"#e8e8e8\" stroke=\"#000000\" points=\"169,-534 115,-534 115,-498 169,-498 169,-534\"/>\n",
       "<text text-anchor=\"start\" x=\"124\" y=\"-513\" font-family=\"Times\" font-size=\"10.00\" fill=\"#000000\">Constant</text>\n",
       "</g>\n",
       "<!-- /outputs/25 -->\n",
       "<g id=\"node9\" class=\"node\">\n",
       "<title>/outputs/25</title>\n",
       "<polygon fill=\"#e8e8e8\" stroke=\"#000000\" points=\"172.5,-451 111.5,-451 111.5,-415 172.5,-415 172.5,-451\"/>\n",
       "<text text-anchor=\"start\" x=\"120\" y=\"-430\" font-family=\"Times\" font-size=\"10.00\" fill=\"#000000\">Unsqueeze</text>\n",
       "</g>\n",
       "<!-- LeNet5/outputs/23&#45;&gt;/outputs/25 -->\n",
       "<g id=\"edge5\" class=\"edge\">\n",
       "<title>LeNet5/outputs/23&#45;&gt;/outputs/25</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M142,-497.9902C142,-487.2963 142,-473.4994 142,-461.3706\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"145.5001,-461.2612 142,-451.2612 138.5001,-461.2613 145.5001,-461.2612\"/>\n",
       "</g>\n",
       "<!-- /outputs/26 -->\n",
       "<g id=\"node10\" class=\"node\">\n",
       "<title>/outputs/26</title>\n",
       "<polygon fill=\"#e8e8e8\" stroke=\"#000000\" points=\"169,-368 115,-368 115,-332 169,-332 169,-368\"/>\n",
       "<text text-anchor=\"start\" x=\"127\" y=\"-347\" font-family=\"Times\" font-size=\"10.00\" fill=\"#000000\">Concat</text>\n",
       "</g>\n",
       "<!-- /outputs/24&#45;&gt;/outputs/26 -->\n",
       "<g id=\"edge6\" class=\"edge\">\n",
       "<title>/outputs/24&#45;&gt;/outputs/26</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M80.1418,-414.9902C91.0401,-403.5401 105.3242,-388.5328 117.42,-375.8245\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"120.2596,-377.9178 124.6188,-368.2612 115.1892,-373.0917 120.2596,-377.9178\"/>\n",
       "</g>\n",
       "<!-- /outputs/25&#45;&gt;/outputs/26 -->\n",
       "<g id=\"edge7\" class=\"edge\">\n",
       "<title>/outputs/25&#45;&gt;/outputs/26</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M142,-414.9902C142,-404.2963 142,-390.4994 142,-378.3706\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"145.5001,-378.2612 142,-368.2612 138.5001,-378.2613 145.5001,-378.2612\"/>\n",
       "</g>\n",
       "<!-- /outputs/26&#45;&gt;LeNet5/outputs/27 -->\n",
       "<g id=\"edge8\" class=\"edge\">\n",
       "<title>/outputs/26&#45;&gt;LeNet5/outputs/27</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M150.4624,-331.9902C155.5888,-321.0802 162.2327,-306.9407 168.0137,-294.6376\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"171.3344,-295.8004 172.4194,-285.2612 164.9989,-292.8234 171.3344,-295.8004\"/>\n",
       "</g>\n",
       "<!-- 4866782375408048177 -->\n",
       "<g id=\"node17\" class=\"node\">\n",
       "<title>4866782375408048177</title>\n",
       "<polygon fill=\"#e8e8e8\" stroke=\"#000000\" points=\"217,-202 145,-202 145,-166 217,-166 217,-202\"/>\n",
       "<text text-anchor=\"start\" x=\"153\" y=\"-181\" font-family=\"Times\" font-size=\"10.00\" fill=\"#000000\">Linear &gt; Relu</text>\n",
       "</g>\n",
       "<!-- LeNet5/outputs/27&#45;&gt;4866782375408048177 -->\n",
       "<g id=\"edge15\" class=\"edge\">\n",
       "<title>LeNet5/outputs/27&#45;&gt;4866782375408048177</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M181,-248.9902C181,-238.2963 181,-224.4994 181,-212.3706\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"184.5001,-212.2612 181,-202.2612 177.5001,-212.2613 184.5001,-212.2612\"/>\n",
       "<text text-anchor=\"middle\" x=\"194.5\" y=\"-223\" font-family=\"Times\" font-size=\"10.00\" fill=\"#000000\">1x120</text>\n",
       "</g>\n",
       "<!-- LeNet5/Sequential[fcn]/ReLU[1]/outputs/30 -->\n",
       "<g id=\"node12\" class=\"node\">\n",
       "<title>LeNet5/Sequential[fcn]/ReLU[1]/outputs/30</title>\n",
       "<polygon fill=\"#e8e8e8\" stroke=\"#000000\" points=\"208,-119 154,-119 154,-83 208,-83 208,-119\"/>\n",
       "<text text-anchor=\"start\" x=\"168\" y=\"-98\" font-family=\"Times\" font-size=\"10.00\" fill=\"#000000\">Linear</text>\n",
       "</g>\n",
       "<!-- LeNet5/Sequential[fcn]/Softmax[3]/outputs/31 -->\n",
       "<g id=\"node13\" class=\"node\">\n",
       "<title>LeNet5/Sequential[fcn]/Softmax[3]/outputs/31</title>\n",
       "<polygon fill=\"#e8e8e8\" stroke=\"#000000\" points=\"208,-36 154,-36 154,0 208,0 208,-36\"/>\n",
       "<text text-anchor=\"start\" x=\"164\" y=\"-15\" font-family=\"Times\" font-size=\"10.00\" fill=\"#000000\">Softmax</text>\n",
       "</g>\n",
       "<!-- LeNet5/Sequential[fcn]/ReLU[1]/outputs/30&#45;&gt;LeNet5/Sequential[fcn]/Softmax[3]/outputs/31 -->\n",
       "<g id=\"edge9\" class=\"edge\">\n",
       "<title>LeNet5/Sequential[fcn]/ReLU[1]/outputs/30&#45;&gt;LeNet5/Sequential[fcn]/Softmax[3]/outputs/31</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M181,-82.9902C181,-72.2963 181,-58.4994 181,-46.3706\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"184.5001,-46.2612 181,-36.2612 177.5001,-46.2613 184.5001,-46.2612\"/>\n",
       "<text text-anchor=\"middle\" x=\"192\" y=\"-57\" font-family=\"Times\" font-size=\"10.00\" fill=\"#000000\">1x10</text>\n",
       "</g>\n",
       "<!-- 13829414639943008022 -->\n",
       "<g id=\"node14\" class=\"node\">\n",
       "<title>13829414639943008022</title>\n",
       "<polygon fill=\"#e8e8e8\" stroke=\"#000000\" points=\"275,-783 191,-783 191,-747 275,-747 275,-783\"/>\n",
       "<text text-anchor=\"start\" x=\"199\" y=\"-762\" font-family=\"Times\" font-size=\"10.00\" fill=\"#000000\">Conv5x5 &gt; Relu</text>\n",
       "</g>\n",
       "<!-- 13829414639943008022&#45;&gt;LeNet5/Sequential[convnet]/MaxPool2d[2]/outputs/13 -->\n",
       "<g id=\"edge10\" class=\"edge\">\n",
       "<title>13829414639943008022&#45;&gt;LeNet5/Sequential[convnet]/MaxPool2d[2]/outputs/13</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M233,-746.9902C233,-736.2963 233,-722.4994 233,-710.3706\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"236.5001,-710.2612 233,-700.2612 229.5001,-710.2613 236.5001,-710.2612\"/>\n",
       "<text text-anchor=\"middle\" x=\"257\" y=\"-721\" font-family=\"Times\" font-size=\"10.00\" fill=\"#000000\">1x6x28x28</text>\n",
       "</g>\n",
       "<!-- 9982070002344264092&#45;&gt;LeNet5/Sequential[convnet]/MaxPool2d[5]/outputs/16 -->\n",
       "<g id=\"edge12\" class=\"edge\">\n",
       "<title>9982070002344264092&#45;&gt;LeNet5/Sequential[convnet]/MaxPool2d[5]/outputs/16</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M233,-580.9902C233,-570.2963 233,-556.4994 233,-544.3706\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"236.5001,-544.2612 233,-534.2612 229.5001,-544.2613 236.5001,-544.2612\"/>\n",
       "<text text-anchor=\"middle\" x=\"259.5\" y=\"-555\" font-family=\"Times\" font-size=\"10.00\" fill=\"#000000\">1x16x10x10</text>\n",
       "</g>\n",
       "<!-- 6016725258550978689&#45;&gt;LeNet5/Sequential[convnet]/MaxPool2d[8]/outputs/19 -->\n",
       "<g id=\"edge14\" class=\"edge\">\n",
       "<title>6016725258550978689&#45;&gt;LeNet5/Sequential[convnet]/MaxPool2d[8]/outputs/19</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M231.6981,-414.9902C230.925,-404.2963 229.9277,-390.4994 229.0509,-378.3706\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"232.5321,-377.9828 228.3201,-368.2612 225.5503,-378.4876 232.5321,-377.9828\"/>\n",
       "<text text-anchor=\"middle\" x=\"254\" y=\"-389\" font-family=\"Times\" font-size=\"10.00\" fill=\"#000000\">1x120x1x1</text>\n",
       "</g>\n",
       "<!-- 4866782375408048177&#45;&gt;LeNet5/Sequential[fcn]/ReLU[1]/outputs/30 -->\n",
       "<g id=\"edge16\" class=\"edge\">\n",
       "<title>4866782375408048177&#45;&gt;LeNet5/Sequential[fcn]/ReLU[1]/outputs/30</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M181,-165.9902C181,-155.2963 181,-141.4994 181,-129.3706\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"184.5001,-129.2612 181,-119.2612 177.5001,-129.2613 184.5001,-129.2612\"/>\n",
       "<text text-anchor=\"middle\" x=\"192\" y=\"-140\" font-family=\"Times\" font-size=\"10.00\" fill=\"#000000\">1x84</text>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<hiddenlayer.graph.Graph at 0x7f6e39cbf048>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import hiddenlayer\n",
    "\n",
    "\n",
    "hiddenlayer.build_graph(LeNet5(), torch.zeros(1, 1, 32, 32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<i>Reference</i>: <a href=\"https://github.com/waleedka/hiddenlayer\">HiddenLayer Documentation</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lecture 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = torch.from_numpy(\n",
    "            np.array(\n",
    "                [\n",
    "                    [0, 0],\n",
    "                    [0, 1],\n",
    "                    [1, 0],\n",
    "                    [1, 1]\n",
    "                ],\n",
    "                dtype=np.float32\n",
    "            )\n",
    "        )\n",
    "\n",
    "outputs = torch.from_numpy(\n",
    "            np.array(\n",
    "                [\n",
    "                    0,\n",
    "                    1,\n",
    "                    1,\n",
    "                    0\n",
    "                ],\n",
    "                dtype=np.float32\n",
    "            )\n",
    "        )\n",
    "\n",
    "weights = torch.randn(1, 2)\n",
    "weights.requires_grad = True\n",
    "\n",
    "bias = torch.randn(1, requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.1457],\n",
       "        [ 0.4265],\n",
       "        [-0.0445],\n",
       "        [ 0.5277]], grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.linear(inputs, weights, bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = F.linear(inputs, weights, bias)\n",
    "loss = (outputs - preds).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AddmmBackward at 0x7f995031c9e8>"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds.grad_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<MeanBackward0 at 0x7f995031cef0>"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss.grad_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.5000, -0.5000]])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lecture 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MNIST Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = torchvision.datasets.MNIST(\n",
    "    './data/mnist',\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=torchvision.transforms.Compose([\n",
    "        torchvision.transforms.Pad(2),\n",
    "        torchvision.transforms.ToTensor()\n",
    "    ])\n",
    ")\n",
    "\n",
    "data_test = torchvision.datasets.MNIST(\n",
    "    './data/mnist',\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=torchvision.transforms.Compose([\n",
    "        torchvision.transforms.Pad(2),\n",
    "        torchvision.transforms.ToTensor()\n",
    "    ])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    data_train,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    num_workers=4\n",
    ")\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    data_test,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    num_workers=4\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GPU Support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cpu')\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "\n",
    "\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cauchy-Schwarz Divergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encodeOneHot(torch_tensor):\n",
    "    a = torch_tensor.cpu().numpy()\n",
    "    \n",
    "    b = np.zeros( ( a.size, 10 ) )\n",
    "    \n",
    "    b[ np.arange(a.size), a ] = 1\n",
    "\n",
    "    return torch.from_numpy(b).float().to(device)\n",
    "\n",
    "\n",
    "class CSD(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        \n",
    "        super(CSD, self).__init__()\n",
    "    \n",
    "    def forward(self, outputs, target):\n",
    "        \n",
    "        y = encodeOneHot(target)\n",
    "                \n",
    "        nom = torch.sum(torch.mm(outputs, y.t()), dim=1)\n",
    "        \n",
    "        denom = torch.norm(outputs, 2) * torch.norm(y, 2)\n",
    "        \n",
    "        return torch.mean(-1 * torch.log(nom / denom))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "network = LeNet5().to(device)\n",
    "optimizer = torch.optim.Adam(network.parameters(), lr=0.0005)\n",
    "criterion = CSD()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Loss: 1.1541\n",
      "Epoch: 2, Loss: 1.1528\n",
      "Epoch: 3, Loss: 1.1498\n",
      "Epoch: 4, Loss: 1.1530\n",
      "Epoch: 5, Loss: 1.1518\n",
      "Epoch: 6, Loss: 1.1510\n",
      "Epoch: 7, Loss: 1.1509\n",
      "Epoch: 8, Loss: 1.1485\n",
      "Epoch: 9, Loss: 1.1516\n",
      "Epoch: 10, Loss: 1.1512\n",
      "Epoch: 11, Loss: 1.1523\n",
      "Epoch: 12, Loss: 1.1494\n",
      "Epoch: 13, Loss: 1.1483\n",
      "Epoch: 14, Loss: 1.1481\n",
      "Epoch: 15, Loss: 1.1491\n",
      "Epoch: 16, Loss: 1.1511\n",
      "Epoch: 17, Loss: 1.1523\n",
      "Epoch: 18, Loss: 1.1503\n",
      "Epoch: 19, Loss: 1.1491\n",
      "Epoch: 20, Loss: 1.1483\n",
      "Epoch: 21, Loss: 1.1509\n",
      "Epoch: 22, Loss: 1.1499\n",
      "Epoch: 23, Loss: 1.1490\n",
      "Epoch: 24, Loss: 1.1473\n",
      "Epoch: 25, Loss: 1.1493\n",
      "Epoch: 26, Loss: 1.1489\n",
      "Epoch: 27, Loss: 1.1476\n",
      "Epoch: 28, Loss: 1.1510\n",
      "Epoch: 29, Loss: 1.1487\n",
      "Epoch: 30, Loss: 1.1483\n",
      "Epoch: 31, Loss: 1.1480\n",
      "Epoch: 32, Loss: 1.1475\n",
      "Epoch: 33, Loss: 1.1489\n",
      "Epoch: 34, Loss: 1.1489\n",
      "Epoch: 35, Loss: 1.1455\n",
      "Epoch: 36, Loss: 1.1491\n",
      "Epoch: 37, Loss: 1.1495\n",
      "Epoch: 38, Loss: 1.1489\n",
      "Epoch: 39, Loss: 1.1491\n",
      "Epoch: 40, Loss: 1.1494\n",
      "Epoch: 41, Loss: 1.1466\n",
      "Epoch: 42, Loss: 1.1504\n",
      "Epoch: 43, Loss: 1.1476\n",
      "Epoch: 44, Loss: 1.1469\n",
      "Epoch: 45, Loss: 1.1475\n",
      "Epoch: 46, Loss: 1.1485\n",
      "Epoch: 47, Loss: 1.1472\n",
      "Epoch: 48, Loss: 1.1468\n",
      "Epoch: 49, Loss: 1.1476\n",
      "Epoch: 50, Loss: 1.1498\n",
      "Epoch: 51, Loss: 1.1485\n",
      "Epoch: 52, Loss: 1.1474\n",
      "Epoch: 53, Loss: 1.1485\n",
      "Epoch: 54, Loss: 1.1486\n",
      "Epoch: 55, Loss: 1.1490\n",
      "Epoch: 56, Loss: 1.1467\n",
      "Epoch: 57, Loss: 1.1481\n",
      "Epoch: 58, Loss: 1.1487\n",
      "Epoch: 59, Loss: 1.1489\n",
      "Epoch: 60, Loss: 1.1468\n",
      "Epoch: 61, Loss: 1.1452\n",
      "Epoch: 62, Loss: 1.1482\n",
      "Epoch: 63, Loss: 1.1486\n",
      "Epoch: 64, Loss: 1.1469\n",
      "Epoch: 65, Loss: 1.1471\n",
      "Epoch: 66, Loss: 1.1463\n",
      "Epoch: 67, Loss: 1.1494\n",
      "Epoch: 68, Loss: 1.1466\n",
      "Epoch: 69, Loss: 1.1429\n",
      "Epoch: 70, Loss: 1.1476\n",
      "Epoch: 71, Loss: 1.1480\n",
      "Epoch: 72, Loss: 1.1443\n",
      "Epoch: 73, Loss: 1.1493\n",
      "Epoch: 74, Loss: 1.1474\n",
      "Epoch: 75, Loss: 1.1467\n",
      "Epoch: 76, Loss: 1.1478\n",
      "Epoch: 77, Loss: 1.1469\n",
      "Epoch: 78, Loss: 1.1498\n",
      "Epoch: 79, Loss: 1.1475\n",
      "Epoch: 80, Loss: 1.1484\n",
      "Epoch: 81, Loss: 1.1476\n",
      "Epoch: 82, Loss: 1.1470\n",
      "Epoch: 83, Loss: 1.1488\n",
      "Epoch: 84, Loss: 1.1471\n",
      "Epoch: 85, Loss: 1.1465\n",
      "Epoch: 86, Loss: 1.1449\n",
      "Epoch: 87, Loss: 1.1467\n",
      "Epoch: 88, Loss: 1.1477\n",
      "Epoch: 89, Loss: 1.1473\n",
      "Epoch: 90, Loss: 1.1462\n",
      "Epoch: 91, Loss: 1.1472\n",
      "Epoch: 92, Loss: 1.1454\n",
      "Epoch: 93, Loss: 1.1473\n",
      "Epoch: 94, Loss: 1.1480\n",
      "Epoch: 95, Loss: 1.1460\n",
      "Epoch: 96, Loss: 1.1465\n",
      "Epoch: 97, Loss: 1.1473\n",
      "Epoch: 98, Loss: 1.1460\n",
      "Epoch: 99, Loss: 1.1491\n",
      "Epoch: 100, Loss: 1.1470\n",
      "Epoch: 101, Loss: 1.1461\n",
      "Epoch: 102, Loss: 1.1442\n",
      "Epoch: 103, Loss: 1.1468\n",
      "Epoch: 104, Loss: 1.1457\n",
      "Epoch: 105, Loss: 1.1444\n",
      "Epoch: 106, Loss: 1.1456\n",
      "Epoch: 107, Loss: 1.1438\n",
      "Epoch: 108, Loss: 1.1450\n",
      "Epoch: 109, Loss: 1.1480\n",
      "Epoch: 110, Loss: 1.1475\n",
      "Epoch: 111, Loss: 1.1462\n",
      "Epoch: 112, Loss: 1.1447\n",
      "Epoch: 113, Loss: 1.1462\n",
      "Epoch: 114, Loss: 1.1478\n",
      "Epoch: 115, Loss: 1.1482\n",
      "Epoch: 116, Loss: 1.1459\n",
      "Epoch: 117, Loss: 1.1472\n",
      "Epoch: 118, Loss: 1.1465\n",
      "Epoch: 119, Loss: 1.1458\n",
      "Epoch: 120, Loss: 1.1471\n",
      "Epoch: 121, Loss: 1.1492\n",
      "Epoch: 122, Loss: 1.1465\n",
      "Epoch: 123, Loss: 1.1479\n",
      "Epoch: 124, Loss: 1.1472\n",
      "Epoch: 125, Loss: 1.1476\n",
      "Epoch: 126, Loss: 1.1467\n",
      "Epoch: 127, Loss: 1.1462\n",
      "Epoch: 128, Loss: 1.1467\n"
     ]
    }
   ],
   "source": [
    "epochs = 128\n",
    "steps = len(train_loader) // BATCH_SIZE\n",
    "\n",
    "network.train(True)\n",
    "\n",
    "for e in range(epochs):\n",
    "    \n",
    "    epoch_loss = 0\n",
    "\n",
    "    performed_steps = 0\n",
    "    \n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        \n",
    "        if i == steps:\n",
    "            break\n",
    "        \n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        outputs = network(images)\n",
    "        \n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss\n",
    "        \n",
    "        performed_steps += 1\n",
    "    \n",
    "    assert performed_steps == steps, \"steps: {} != {}\".format(steps, performed_steps)\n",
    "    \n",
    "    print(\"Epoch: {}, Loss: {:0.4f}\".format(\n",
    "        e + 1,\n",
    "        epoch_loss / steps\n",
    "    ))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 1.15, Acc: 92.20%\n"
     ]
    }
   ],
   "source": [
    "avg_loss = 0\n",
    "avg_acc = 0\n",
    "\n",
    "network.train(False)\n",
    "\n",
    "with torch.no_grad():\n",
    "    \n",
    "    steps = 0\n",
    "\n",
    "    for images, labels in test_loader:\n",
    "        \n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        outputs = network(images)\n",
    "\n",
    "        avg_loss += criterion(outputs, labels)\n",
    "\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        avg_acc += preds.eq(labels).sum().item()\n",
    "        \n",
    "        steps += 1\n",
    "\n",
    "\n",
    "print(\"Loss: {:0.2f}, Acc: {:.2%}\".format(\n",
    "    avg_loss / steps,\n",
    "    avg_acc / (steps * BATCH_SIZE)\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read More\n",
    "\n",
    "<ul>\n",
    "    <li>Robert Jenssen, Jose C. Principe, Deniz Erdogmus, Torbjørn Eltoft, The Cauchy–Schwarz divergence and Parzen windowing: Connections to graph theory and Mercer kernels, Journal of the Franklin Institute, Volume 343, Issue 6, 2006, Pages 614-629, ISSN 0016-0032, https://doi.org/10.1016/j.jfranklin.2006.03.018.</li>\n",
    "    <li>Jenssen, R., Eltoft, T., Erdogmus, D. et al. J VLSI Sign Process Syst Sign Image Video Technol (2006) 45: 49. https://doi.org/10.1007/s11265-006-9771-8</li>\n",
    "    <li>Janocha, K., & Czarnecki, W. (2017). On Loss Functions for Deep Neural Networks in Classification. CoRR, abs/1702.05659.</li>\n",
    "    <li>Lecun, Yann & Bottou, Leon & Bengio, Y & Haffner, Patrick. (1998). Gradient-Based Learning Applied to Document Recognition. Proceedings of the IEEE. 86. 2278 - 2324. 10.1109/5.726791. http://yann.lecun.com/exdb/publis/pdf/lecun-01a.pdf </li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Course Discussions\n",
    "\n",
    "Slack Channel: <a href=\"https://mqubits.slack.com/join/shared_invite/enQtNjU2MTQ3ODgxMjY3LTgyMGM3MzFjOTQ3OTdlYjVmMGJkZWI0NzgxNDAyNzEzYWVlNjQwOGQ5ZmY0MzFiYjc5OGNkZmY3YzQ5M2RhOWM\">https://mqubits.slack.com/join/shared_invite/enQtNjU2MTQ3ODgxMjY3LTgyMGM3MzFjOTQ3OTdlYjVmMGJkZWI0NzgxNDAyNzEzYWVlNjQwOGQ5ZmY0MzFiYjc5OGNkZmY3YzQ5M2RhOWM</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Google Colab\n",
    "\n",
    "<a href=\"https://colab.research.google.com/drive/1BON2RGHeRqS1tM3raz6HSpO8Xfz5-vYy\">https://colab.research.google.com/drive/1BON2RGHeRqS1tM3raz6HSpO8Xfz5-vYy</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
